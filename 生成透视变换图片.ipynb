{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../MyLibrary/')\n",
    "import siannodel.img_process.opencv_extend as mycv\n",
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据生成测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen import PhotoGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_config = EasyDict({\n",
    "    'warp_scale':0.1,\n",
    "    'image_size':[768,1024],\n",
    "    'img_dirs':[\n",
    "        '/home/renhui/File/data/text_detection/train_data/data1_PNG/',\n",
    "    ],\n",
    "    'bg_img_dirs':[\n",
    "        '/home/renhui/File/data/text_detection/background/',\n",
    "    ],\n",
    "})\n",
    "photo_gen = PhotoGenerator(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = photo_gen.gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 768\n"
     ]
    }
   ],
   "source": [
    "tmp = gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append('/home/renhui/File/MyLibrary/')\n",
    "import siannodel.img_process.opencv_extend as mycv\n",
    "import siannodel.ml.tf_estimator as myestimator\n",
    "from siannodel.mylogger import *\n",
    "from easydict import EasyDict\n",
    "import siannodel.mytime as mytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     4,
     16,
     23
    ]
   },
   "outputs": [],
   "source": [
    "class Net(myestimator.BaseNet):\n",
    "    def __init__(self, config):\n",
    "        super(Net,self).__init__(config)\n",
    "        \n",
    "    def conv2d(self, input_tensor, filters, name, training):\n",
    "        with tf.name_scope(name):\n",
    "            output_tensor = tf.layers.conv2d(inputs=input_tensor,\n",
    "                                             filters=filters,\n",
    "                                             kernel_size=(3,3),\n",
    "                                             padding='same',\n",
    "                                             activation=None)\n",
    "            output_tensor = tf.layers.batch_normalization(output_tensor,\n",
    "                                                          training=training)\n",
    "            output_tensor = tf.nn.relu(output_tensor)\n",
    "        return output_tensor\n",
    "    \n",
    "    def upsample_and_concat(self, x1, x2, filters):\n",
    "        deconv = tf.layers.conv2d_transpose(x1, filters, (2,2),\n",
    "                                            strides=2)\n",
    "        output_tensor = tf.concat([deconv,x2], 3)\n",
    "        output_tensor.set_shape([None,None,None,filters*2])\n",
    "        return output_tensor\n",
    "    \n",
    "    def __call__(self, x, training):\n",
    "        network = {}\n",
    "        network['conv1'] = self.conv2d(x, 32, 'conv1_1', training)\n",
    "        network['conv1'] = self.conv2d(network['conv1'], \n",
    "                                       32, 'conv1_2', training)\n",
    "        network['pool1'] = tf.layers.max_pooling2d(inputs=network['conv1'],\n",
    "                                                   pool_size=[2,2], \n",
    "                                                   strides=2,\n",
    "                                                   name='pool1')\n",
    "        network['conv2'] = self.conv2d(network['pool1'], 64, \n",
    "                                       'conv2_1', training)\n",
    "        network['conv2'] = self.conv2d(network['conv2'], 64, \n",
    "                                       'conv2_2', training)\n",
    "        network['pool2'] = tf.layers.max_pooling2d(inputs=network['conv2'],\n",
    "                                                   pool_size=[2,2], \n",
    "                                                   strides=2,\n",
    "                                                   name='pool2')\n",
    "        network['conv3'] = self.conv2d(network['pool2'], 128, \n",
    "                                       'conv3_1', training)\n",
    "        network['conv3'] = self.conv2d(network['conv3'], 128, \n",
    "                                       'conv3_2', training)\n",
    "        network['pool3'] = tf.layers.max_pooling2d(inputs=network['conv3'],\n",
    "                                                   pool_size=[2,2], \n",
    "                                                   strides=2,\n",
    "                                                   name='pool3')\n",
    "        network['conv4'] = self.conv2d(network['pool3'], 256, \n",
    "                                       'conv4_1', training)\n",
    "        network['conv4'] = self.conv2d(network['conv4'], 256, \n",
    "                                       'conv4_2', training)\n",
    "        network['pool4'] = tf.layers.max_pooling2d(inputs=network['conv4'],\n",
    "                                                   pool_size=[2,2], \n",
    "                                                   strides=2,\n",
    "                                                   name='pool4')\n",
    "    \n",
    "        network['conv5'] = self.conv2d(network['pool4'], 512, \n",
    "                                       'conv5_1', training)\n",
    "        network['conv5'] = self.conv2d(network['conv5'], 512, \n",
    "                                       'conv5_2', training)\n",
    "        \n",
    "        network['up6'] = self.upsample_and_concat(network['conv5'],\n",
    "                                                  network['conv4'],\n",
    "                                                  256)\n",
    "        network['conv6'] = self.conv2d(network['up6'], 256, \n",
    "                                       'conv6_1', training)\n",
    "        network['conv6'] = self.conv2d(network['conv6'], 256, \n",
    "                                       'conv6_2', training)\n",
    "        \n",
    "        network['up7'] = self.upsample_and_concat(network['conv6'],\n",
    "                                                  network['conv3'],\n",
    "                                                  128)\n",
    "        network['conv7'] = self.conv2d(network['up7'], 128, \n",
    "                                       'conv7_1', training)\n",
    "        network['conv7'] = self.conv2d(network['conv7'], 128, \n",
    "                                       'conv7_2', training)\n",
    "        \n",
    "        network['up8'] = self.upsample_and_concat(network['conv7'],\n",
    "                                                  network['conv2'],\n",
    "                                                  64)\n",
    "        network['conv8'] = self.conv2d(network['up8'], 64, \n",
    "                                       'conv8_1', training)\n",
    "        network['conv8'] = self.conv2d(network['conv8'], 64, \n",
    "                                       'conv8_2', training)\n",
    "        \n",
    "        network['up9'] = self.upsample_and_concat(network['conv8'],\n",
    "                                                  network['conv1'],\n",
    "                                                  32)\n",
    "        network['conv9'] = self.conv2d(network['up9'], 32, \n",
    "                                       'conv9_1', training)\n",
    "        network['conv9'] = self.conv2d(network['conv9'], 32, \n",
    "                                       'conv9_2', training)\n",
    "        \n",
    "        network['score_map'] = tf.layers.conv2d(network['conv9'], 1, (1,1),\n",
    "                                                padding='same',\n",
    "                                                activation=None,\n",
    "                                                name='score_map')\n",
    "        network['score_map'] = tf.nn.sigmoid(network['score_map'])\n",
    "        \n",
    "        network['flat'] = tf.layers.flatten(network['conv9'], name='flat')\n",
    "        network['fc1'] = tf.layers.dense(inputs=network['flat'], units=1024,\n",
    "                                         activation=tf.nn.relu, name='fc1')\n",
    "        network['fc2'] =  tf.layers.dense(inputs=network['fc1'], units=256,\n",
    "                                         activation=tf.nn.relu, name='fc2')\n",
    "        network['M'] = tf.layers.dense(inputs=network['fc2'], units=8,\n",
    "                                         activation=tf.nn.relu, name='M')\n",
    "        network['pts'] = tf.layers.dense(inputs=network['fc2'], units=8,\n",
    "                                         activation=tf.nn.relu, name='pts')\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
